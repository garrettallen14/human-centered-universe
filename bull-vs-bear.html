<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI's Crossroads: Analyzing Bullish and Bearish Perspectives Regarding the Next Decade of AI</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono&display=swap" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Wittgenstein:ital,wght@0,400..900;1,400..900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="content-wrapper">
        <header>
            <h1>Human Centered Universe</h1>
        </header>
        <nav>
            <a href="index.html">Home</a>
            <a href="index.html#about">About</a>
        </nav>
        <main id="content">
            <article class="full-article">
                <h2>AI's Crossroads: Analyzing Bullish and Bearish Perspectives Regarding the Next Decade of AI</h2>
                <div class="date">12 Jul 2024</div>
                
                <nav class="table-of-contents">
                    <h3>Contents</h3>
                    <ol>
                        <li><a href="#executive-summary">Executive Summary</a></li>
                        <li><a href="#introduction">Introduction</a></li>
                        <li><a href="#background">Background</a></li>
                        <li><a href="#key-disagreements">Key Disagreements</a>
                            <ol>
                                <li><a href="#economic-impact">Skepticism of AI's Economic Impact</a></li>
                                <li><a href="#costs-benefits">High Costs vs. Limited Benefits</a></li>
                                <li><a href="#progress-expectations">Slow Progress Expectations</a></li>
                                <li><a href="#task-automation">Limited Task Automation</a></li>
                                <li><a href="#transformative-potential">Doubt in Transformative Potential</a></li>
                            </ol>
                        </li>
                        <li><a href="#commentary">Commentary</a></li>
                        <li><a href="#conclusion">Conclusion</a></li>
                    </ol>
                </nav>
                
                <section id="executive-summary" class="article-content">
                    <h3>Executive Summary</h3>
                    <p>Goldman Sachs' (GS) recent <a href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf?ref=wheresyoured.at" style="text-decoration: underline; color: inherit;">GenAI report</a> highlights two pessimistic outlooks on the future of AI development. In this article, we contrast these viewpoints with the opinions held by scaling-law optimists.</p>
                    <ul>
                        <li><strong>Economic Impact:</strong> GS predicts modest impact (0.53% TFP gain over 10 years), while optimists expect transformative change.</li>
                        <li><strong>Cost vs. Benefit:</strong> GS sees high costs and limited benefits, while optimists point to rapidly decreasing costs and increasing capabilities.</li>
                        <li><strong>Progress Rate:</strong> GS expects slow progress, while optimists predict rapid advancements based on scaling trends.</li>
                        <li><strong>Task Automation:</strong> GS predicts limited automation (4.6% of tasks by 2034), while optimists expect widespread automation of cognitive tasks.</li>
                        <li><strong>Transformative Potential:</strong> GS doubts AI's ability to replace human reasoning, while optimists foresee AGI by as soon as 2027.</li>
                    </ul>
                </section>

                <section id="introduction" class="article-content">
                    <h3>Introduction</h3>
                    <p>Last month, two starkly contrasting visions of AI's future emerged. On one side, a starry-eyed boy-genius is claiming "AGI by 2027" and advocating for large-scale multinational mobilization. On the other, two old-school industry experts argue that GenAI is nothing more than a growing bubble, ripe for bursting.</p>
                    <p>For the AGI-is-imminent camp, humanity is hurtling towards superintelligence at a breakneck pace. The GenAI-is-a-bubble camp, however, contends that despite the substantial capital being poured into AI development, the estimated $1tn worth of incoming investment will ultimately fail to return a sufficient return on investment.</p>
                    <p>In this article, we'll explore these divergent viewpoints.</p>
                </section>

                <section class="tweet-embed">
                    <blockquote class="twitter-tweet" data-dnt="true">
                        <p lang="en" dir="ltr">Goldman Sachs bearish on AI:<br><br>&quot;What $1tn problem will AI solve?&quot;<br><br>Meanwhile at OpenAI:<br><br>&quot;We&#39;re on track to build AGIs that are vastly more capable than humans, and expect this to happen in the next 5-10 years&quot;<br><br>This gap in perception is interesting. What do you think? <a href="https://t.co/BvZT90t9CS">pic.twitter.com/BvZT90t9CS</a></p>&mdash; Garry Tan 陈嘉兴 (@garrytan) <a href="https://twitter.com/garrytan/status/1810514916291592646?ref_src=twsrc%5Etfw">April 17, 2024</a>
                    </blockquote>
                </section>

                <div class="ellipsis">...</div>

                <section id="background" class="article-content">
                    <h3>Background</h3>
                    <p>On June 4th, 2024, former OpenAI Superalignment team member Leopold Aschenbrenner released <a href="https://situational-awareness.ai/" style="text-decoration: underline; color: inherit;">Situational Awareness: The Decade Ahead</a>, a five-part series outlining his grand vision for the future of AI development. Aschenbrenner's timeline is ambitious:</p>
                    <ul>
                        <li>"AGI by 2027 is strikingly plausible."</li>
                        <li>"AI progress won't stop at human-level. Hundreds of millions of AGIs could automate AI research, compressing a decade of algorithmic progress (5+ OOMs) into ≤1 year"</li>
                        <li>"As the race to AGI intensifies ... by 27/28 we'll get some form of government AGI project. No startup can handle superintelligence. Somewhere in a SCIF, the endgame will be on."</li>
                    </ul>
                    <p>Just three weeks later, Goldman Sachs released their report presenting some far more pessimistic outlooks on AI's potential. While most interviews in the report were cautious, MIT Professor Darron Acemoglu and Goldman Sachs Head of Global Equity Research Jim Covello stood out for their particularly skeptical views on GenAI's future.</p>
                    <p>In the following sections, we'll explore the key differences between Aschenbrenner, Acemoglu, and Covello's perspectives to understand where the lines are drawn. While <span class="popup-trigger"><span class="dotted-underline">Aschenbrenner's claims have been well-documented in current discourse</span><span class="popup-content">See discussions: 
                        <a href="https://www.lesswrong.com/posts/Yig9oa4zGE97xM2os/response-to-aschenbrenner-s-situational-awareness" target="_blank">Response to Aschenbrenner's "Situational Awareness"</a><br> ...
                        <a href="https://www.lesswrong.com/posts/i5pccofToYepythEw/against-aschenbrenner-how-situational-awareness-constructs-a" target="_blank">Against Aschenbrenner: How Situational Awareness Constructs a Flawed Narrative that Undermines Safety and Threatens Humanity</a>
                        </span></span>, I've yet to find a thorough examination of the Goldman Sachs' skeptics' arguments. Therefore, I'll provide additional commentary on what I believe to be flaws in the Bubble camp's reasoning.</p>
                    <p class="note"><em>Note: An Order of Magnitude (OOM) is a 10x increase. For example, a 5 OOM increase signifies to a 10^5 = 100,000x increase in capabilities. This is typically measured in terms of computational efficiency.</em></p>
                </section>

                <section id="key-disagreements" class="article-content">
                    <h3>Key Disagreements</h3>
                    
                    <h4>Skepticism of AI's Economic Impact</h4>
                    <p>In his paper, <a href="https://economics.mit.edu/sites/default/files/2024-05/The%20Simple%20Macroeconomics%20of%20AI.pdf" style="text-decoration: underline; color: inherit;">The Simple Macroeconomics of AI</a>, Darron Acemoglu predicts a modest impact, estimating <span class="popup-trigger"><span class="dotted-underline">Total Factor Productivity (TFP) gains of less than 0.53% over the next 10 years</span>.<span class="popup-content">"Consequently, predicted TFP gains over the next 10 years are even more modest and are predicted to be less than 0.53%."</span></span> He assumes <span class="popup-trigger"><span class="dotted-underline">AI will only perform 4.6% of total tasks in the current economy by 2034</span><span class="popup-content">"I arrive at the GDP share of tasks impacted by AI within the next 10 years as 0.23 * 0.200 = 4.6% of all tasks (or occupations)."</span></span>. In his interview with GS, Jim Covello also doubts AI's ability to improve employee productivity, stating: "I don't think the technology is, or will likely be, smart enough to make employees smarter."</p>
                    <p>In stark contrast, Aschenbrenner predicts a massive economic impact, suggesting "AGI by 2027 is strikingly plausible" and envisioning "Hundreds of millions of AGIs could automate AI research, compressing a decade of algorithmic progress (5+ OOMs (Orders of Magnitude)) into ≤1 year." An automated AI research workforce would not only have a transformative effect on our economy, but it may alter the meaning of the Human condition as a whole.</p>

                    <h4>High Costs vs. Limited Benefits</h4>
                    <p>Acemoglu believes costs won't significantly decrease, excluding cost reductions entirely from his 10-year forecast (!!!). Covello estimates a $1 trillion AI infrastructure buildout, questioning what "$1 trillion problem" AI will solve. He claims current AI applications are inefficient, citing examples where AI updates data "more quickly than doing so manually, but at six times the cost."</p>
                    <p>Aschenbrenner argues the opposite -- costs are already rapidly decreasing:</p>
                    <ul>
                        <li>"...enormous amounts of algorithmic progress is possible and happening in general."</li>
                        <li>"...it's often the case that an algorithmic improvement is both a training efficiency gain and an inference efficiency, for example by reducing the number of parameters necessary."</li>
                        <li>GPT-4 on release cost ~the same as GPT-3 when it was released, despite an enormous performance increase.</li>
                        <li>Since GPT-4 release, prices have fallen another 6x/4x (input/output) with the release of 4o.</li>
                        <li>Gemini 1.5 Flash offers GPT-3.75 level performance, while costing 85x/57x less than the original GPT-4.</li>
                    </ul>
                    
                    <div class="centered-image">
                        <img src="./imgs/cost_improvements.jpg" alt="Cost Improvements Graph">
                        <p class="image-caption">Figure 1: In less than two years, we have experienced almost an 1000x decrease in the cost of models with similar capabilities. (Source: Situational Awareness)</p>
                    </div>
                    
                    <h4>Slow Progress Expectations</h4>
                    <p>Acemoglu <span class="popup-trigger"><span class="dotted-underline">assumes AI will not create any new tasks or products by 2034</span><span class="popup-content">"Productivity improvements from new tasks and new products, which have been important for previous transformative technologies, such as electricity and the Internet, are not incorporated into my estimates."</span></span>. Covello believes progress will be slow due to <span class="popup-trigger"><span class="dotted-underline">lack of competition</span><span class="popup-content">"Nvidia is the only company currently capable of producing the GPUs that power AI ... there's a big leap from where we are today given that chip companies have tried and failed to dethrone Nvidia from its dominant GPU position for the last 10 years."</span></span>.</p>
                    <p>Aschenbrenner predicts rapid progress, extrapolating from current scaling trends and expecting "3-6 OOMs of base effective compute scaleup" by the end of 2027. Again, 3-6 OOMs means 1,000x - 1,000,000x!</p>
                    
                    <div class="centered-image">
                        <img src="./imgs/base_compute_scaleup.png" alt="Base Compute Scaleup Graph">
                        <p class="image-caption">Figure 2: Best estimates for projected base effective compute scaleups. (Source: Situational Awareness)</p>
                    </div>

                    <h4>Limited Task Automation</h4>
                    <p>Acemoglu predicts AI will only perform 4.6% of total tasks in the current economy by 2034 and assumes AI won't create any new tasks or products. Covello believes AI is limited in complex tasks, stating "Even basic summarization tasks often yield illegible and nonsensical results".</p>
                    <p>Aschenbrenner predicts widespread automation, stating, "We are on course for AGI by 2027. These AI systems will basically be able to automate basically all cognitive jobs (think: all jobs that could be done remotely)."</p>

                    <h4>Doubt in Transformative Potential</h4>
                    <p>Acemoglu and Covello express strong doubts about AI's transformative potential, with Covello stating, "I struggle to believe that the technology will ever achieve the cognitive reasoning required to substantially augment or replace human interactions."</p>
                    <p>Aschenbrenner believes in AI's transformative potential, predicting that "In 2027, a leading AI lab will be able to train GPT-4-level model in a minute…"</p>
                </section>

                <section id="commentary" class="article-content">
                    <section id="commentary" class="article-content">
                        <h3>Commentary</h3>
                        <p>While the skeptics raise valid concerns, their arguments seem to overlook several crucial points:</p>
                        <ul>
                        <li><strong>Cost Reductions:</strong> Discounting the possibility of significant cost reductions over the next decade seems naive. We already have experienced dramatic cost reductions in API prices, which, while not an exact measure of compute efficiencies, are a great indicator of inference efficiency gains—arguably the main economic driver.</li>
                        <li><strong>Technology Cost Trends:</strong> Covello's claim that "The idea that technology typically starts out expensive before becoming cheaper is revisionist history" is demonstrably false. Actually a pretty ridiculous claim, particularly when discussing compute costs.</li>
                        <li><strong>Competition and Innovation:</strong> Covello's assertion that Nvidia faces no competition ignores the reality of the tech industry. Nvidia itself has stated that they are "2-3 generations ahead of the competition, and intend to stay that way, so we are innovating faster than ever."</li>
                        <div class="centered-image">
                            <img src="./imgs/nvidia_scaleup.png" alt="Nvidia Scaleup Graph">
                            <p class="image-caption">Figure 3: Single-Chip inference performance increases over the last 10 years. (Source: Bill Dally | Directions in Deep Learning Hardware)</p>
                        </div>
                        <li><strong>Task Automation:</strong> The striking difference between the skeptics' and optimists' views on task automation highlights the uncertainty in this field. However, recent advancements suggest that AI's capabilities are expanding rapidly, making Aschenbrenner's predictions more plausible than they might initially appear.</li>
                        <li><strong>Transformative Potential:</strong> The skeptics seem to focus on AI's current limitations without fully considering its potential for rapid improvement. As Aschenbrenner notes, we are "racing through the OOMs," and the possibility of AGI by 2027 is based on trend extrapolation rather than "esoteric beliefs."</li>
                        <div class="centered-image">
                            <img src="./imgs/counting_the_ooms.png" alt="Counting the OOMs">
                            <p class="image-caption">Figure 4: OpenAI's Sora architecture performance with respect to base compute applied. (Source: Situational Awareness)</p>
                        </div>
                    </ul>
                </section>

                <section id="conclusion" class="article-content">
                    <h3>Conclusion</h3>
                    <p>While it's crucial to approach AI development with a critical eye, the arguments put forth by the GenAI-is-a-bubble camp seem to underestimate the potential for rapid progress and transformative change.</p>
                    <p>As we move forward, it's important to continue monitoring these developments critically.</p>
                    <p>We must remain cognizant of the possibility that AI's impact may be far more significant and arrive much sooner than the skeptics predict. The coming years will undoubtedly be crucial in determining which camp's vision of the future proves more accurate.</p>
                </section>
            </article>
        </main>
    </div>
    <script src="popup.js"></script>
    <script src="script.js"></script>
    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</body>
</html>